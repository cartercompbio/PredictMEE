{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Train-a-bi-LSTM-to-predict-short-entities\" data-toc-modified-id=\"Train-a-bi-LSTM-to-predict-short-entities-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Train a bi-LSTM to predict short entities<br></a></span></li><li><span><a href=\"#Set-up\" data-toc-modified-id=\"Set-up-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Set up</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-necessry-packages\" data-toc-modified-id=\"Import-necessry-packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import necessry packages</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Load-in-data\" data-toc-modified-id=\"Load-in-data-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Load in data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-in-the-BioSample-annotations-and-build-dataframe\" data-toc-modified-id=\"Read-in-the-BioSample-annotations-and-build-dataframe-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Read in the BioSample annotations and build dataframe</a></span></li><li><span><a href=\"#Read-in-metadata-on-BioSample-entries-that-will-allow-us-to-cap-on-study\" data-toc-modified-id=\"Read-in-metadata-on-BioSample-entries-that-will-allow-us-to-cap-on-study-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Read in metadata on BioSample entries that will allow us to cap on study</a></span></li><li><span><a href=\"#Read-in-embeddings\" data-toc-modified-id=\"Read-in-embeddings-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Read in embeddings</a></span></li><li><span><a href=\"#Import-merging-of-entities-from-file\" data-toc-modified-id=\"Import-merging-of-entities-from-file-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>Import merging of entities from file</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-pre-processing\" data-toc-modified-id=\"Data-pre-processing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data pre-processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Filter-out-non-valid-attributes\" data-toc-modified-id=\"Filter-out-non-valid-attributes-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Filter out non-valid attributes</a></span></li><li><span><a href=\"#-Supp-Figure-1A--Cap-at-100-samples-per-study-to-avoid-study-bias\" data-toc-modified-id=\"-Supp-Figure-1A--Cap-at-100-samples-per-study-to-avoid-study-bias-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><font color=\"red\"> Supp Figure 1A </font> Cap at 100 samples per study to avoid study bias</a></span></li><li><span><a href=\"#Filter-out-unwanted-training-examples-and-replace-all-white-space-with-'-'\" data-toc-modified-id=\"Filter-out-unwanted-training-examples-and-replace-all-white-space-with-'-'-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Filter out unwanted training examples and replace all white space with ' '</a></span></li><li><span><a href=\"#Take-only-values-between-length-2-and-7\" data-toc-modified-id=\"Take-only-values-between-length-2-and-7-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Take only values between length 2 and 7</a></span></li><li><span><a href=\"#Filter-out-test-set-examples\" data-toc-modified-id=\"Filter-out-test-set-examples-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Filter out test set examples</a></span></li><li><span><a href=\"#Replace-whitespace-with-'-'\" data-toc-modified-id=\"Replace-whitespace-with-'-'-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Replace whitespace with ' '</a></span></li><li><span><a href=\"#Final-dataset\" data-toc-modified-id=\"Final-dataset-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Final dataset</a></span></li></ul></li><li><span><a href=\"#Train/val-split\" data-toc-modified-id=\"Train/val-split-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Train/val split</a></span><ul class=\"toc-item\"><li><span><a href=\"#Start-by-pulling-out-only-samples-that-are-in-our-dataset-from-technical-metadata,-that-has-studies-in-it\" data-toc-modified-id=\"Start-by-pulling-out-only-samples-that-are-in-our-dataset-from-technical-metadata,-that-has-studies-in-it-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Start by pulling out only samples that are in our dataset from technical metadata, that has studies in it</a></span></li><li><span><a href=\"#Get-unique-studies\" data-toc-modified-id=\"Get-unique-studies-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Get unique studies</a></span></li><li><span><a href=\"#Select-studies-to-use-to-train-and-validate\" data-toc-modified-id=\"Select-studies-to-use-to-train-and-validate-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Select studies to use to train and validate</a></span></li><li><span><a href=\"#Generate-training-and-val-dataframes\" data-toc-modified-id=\"Generate-training-and-val-dataframes-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Generate training and val dataframes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-set\" data-toc-modified-id=\"Training-set-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Training set</a></span></li><li><span><a href=\"#Validation-set\" data-toc-modified-id=\"Validation-set-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Validation set</a></span></li><li><span><a href=\"#Supp.-Figure-1B-Class-balance\" data-toc-modified-id=\"Supp.-Figure-1B-Class-balance-4.4.3\"><span class=\"toc-item-num\">4.4.3&nbsp;&nbsp;</span><font color=\"red\">Supp. Figure 1B</font> Class balance</a></span></li></ul></li></ul></li><li><span><a href=\"#Train-the-model\" data-toc-modified-id=\"Train-the-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Train the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-set-up\" data-toc-modified-id=\"Model-set-up-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Model set-up</a></span></li><li><span><a href=\"#Model-training\" data-toc-modified-id=\"Model-training-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Model training</a></span></li><li><span><a href=\"#Model-saving\" data-toc-modified-id=\"Model-saving-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Model saving</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a bi-LSTM to predict short entities<br>\n",
    "Adam Klie<br>\n",
    "11/17/2019<br>\n",
    "Updated: 08/31/2020\n",
    "Script to train a model based on merged entities passed in and training set decided on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessry packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:32:02.683400Z",
     "start_time": "2021-03-01T20:31:50.224046Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential, model_from_json, load_model\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import preprocessing, metrics\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "    \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:32:02.835163Z",
     "start_time": "2021-03-01T20:32:02.697752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to build LSTM model.\n",
    "# embeddings: an mxn matrix of word embeddings with m words and n features for each word (this case is 5443656 x 200)\n",
    "# shape: parameter split into number of hidden units, \n",
    "def compile_lstm(embeddings, shape, settings):  # function definition\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(embeddings.shape[0],\n",
    "                        embeddings.shape[1],\n",
    "                        input_length=shape['max_length'],\n",
    "                        trainable=False,\n",
    "                        weights=[embeddings],\n",
    "                        mask_zero=True))\n",
    "    \n",
    "    #the same dense layer is first applied extract the most useful info from embedding layers\n",
    "    model.add(TimeDistributed(Dense(shape['nr_hidden'], use_bias=False)))\n",
    "    model.add(Bidirectional(LSTM(shape['nr_hidden'],\n",
    "                                 recurrent_dropout=settings['dropout'],\n",
    "                                 dropout=settings['dropout'])))\n",
    "    model.add(Dense(shape['nr_class'], activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(lr=settings['lr']), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_features(docs, max_length):\n",
    "    docs = list(docs)\n",
    "    Xs = np.zeros((len(docs), max_length), dtype='int32')\n",
    "    for i, doc in tqdm(enumerate(docs),total=len(docs)):\n",
    "        j = 0\n",
    "        for token in doc:\n",
    "            ##rever to word vector\n",
    "            vector_id = token.vocab.vectors.find(key=token.orth)\n",
    "            if vector_id >= 0:\n",
    "                Xs[i, j] = vector_id\n",
    "            else:\n",
    "                Xs[i, j] = 0\n",
    "            j += 1\n",
    "            if j >= max_length:\n",
    "                break\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:32:02.932812Z",
     "start_time": "2021-03-01T20:32:02.838665Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib as mpl\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 6)\n",
    "rcParams['figure.dpi'] = 600 \n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['font.size'] = 18\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['font.family'] = 'StixGeneral'\n",
    "\n",
    "rcParams['axes.labelsize'] = 36\n",
    "rcParams['ytick.labelsize'] = 30\n",
    "rcParams['xtick.labelsize'] = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the BioSample annotations and build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:32:15.920749Z",
     "start_time": "2021-03-01T20:32:02.942844Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in pandas Series from file\n",
    "SRS_dir = \"../data/sra/allSRS_05_15_2018.pickle\"\n",
    "allSRS = pd.read_pickle(SRS_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in metadata on BioSample entries that will allow us to cap on study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:32:22.306959Z",
     "start_time": "2021-03-01T20:32:15.928471Z"
    }
   },
   "outputs": [],
   "source": [
    "sra_dump_pickle_dir = '../data/sra/sra_dump.pickle'\n",
    "technical_meta_data_df = pd.read_pickle(sra_dump_pickle_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:33:23.404740Z",
     "start_time": "2021-03-01T20:32:22.310661Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../data/wikipedia-pubmed-and-PMC-w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import merging of entities from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:33:24.139977Z",
     "start_time": "2021-03-01T20:33:23.407327Z"
    }
   },
   "outputs": [],
   "source": [
    "model_iter = '11_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:33:24.308112Z",
     "start_time": "2021-03-01T20:33:24.142672Z"
    }
   },
   "outputs": [],
   "source": [
    "grouping_df = pd.read_csv('../results/embedding/{model}/0.8_entity_merging.csv'.format(model = model_iter))\n",
    "#grouping_df = pd.read_csv('../../deep_clean/results/model_v1/merging/entity_merging_model_v1.csv')\n",
    "myAttribs = grouping_df.attribute.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out non-valid attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:33:26.213330Z",
     "start_time": "2021-03-01T20:33:24.310884Z"
    }
   },
   "outputs": [],
   "source": [
    "attribute_m = allSRS.index.get_level_values(1).isin(myAttribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:33:29.106177Z",
     "start_time": "2021-03-01T20:33:26.215397Z"
    }
   },
   "outputs": [],
   "source": [
    "subset_SRS = allSRS[attribute_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Supp Figure 1A </font> Cap at 100 samples per study to avoid study bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:33:34.021101Z",
     "start_time": "2021-03-01T20:33:29.109814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples left after capping: 2348023\n"
     ]
    }
   ],
   "source": [
    "max_sample_per_study_n = 100\n",
    "capped_samples = technical_meta_data_df.groupby('Study').head(n = max_sample_per_study_n)['Sample']\n",
    "print(\"Number of samples left after capping: %d\" % (len(capped_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:33:35.946943Z",
     "start_time": "2021-03-01T20:33:34.024418Z"
    }
   },
   "outputs": [],
   "source": [
    "study_distr = technical_meta_data_df.groupby('Study').head(n = max_sample_per_study_n)[\"Study\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:33:39.833146Z",
     "start_time": "2021-03-01T20:33:35.949317Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "ax = sns.distplot(list(study_distr.values), kde=False)\n",
    "\n",
    "ax.set_ylabel('Frequency', fontsize = 24)\n",
    "ax.set_xlabel('Samples per Study', fontsize = 24)\n",
    "plt.savefig('../doc/figures/Supplementary/Supp_Figure1A.eps', dpi=600, bbox_inches=\"tight\")\n",
    "plt.savefig('../doc/figures/Supplementary/Supp_Figure1A.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:33:42.185119Z",
     "start_time": "2021-03-01T20:33:39.836957Z"
    }
   },
   "outputs": [],
   "source": [
    "capped_m = subset_SRS.index.get_level_values(0).isin(capped_samples.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:33:43.484312Z",
     "start_time": "2021-03-01T20:33:42.187947Z"
    }
   },
   "outputs": [],
   "source": [
    "subset_SRS = subset_SRS[capped_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out unwanted training examples and replace all white space with ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:33:43.559811Z",
     "start_time": "2021-03-01T20:33:43.487358Z"
    }
   },
   "outputs": [],
   "source": [
    "filterTextL = ['not collected','not applicable','missing','n[/]?a','unknown', '-', '--', 'none', 'no']\n",
    "filterTextRegex = \"|\".join(map(lambda myStr:'(?:{})'.format(myStr), filterTextL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:01.964037Z",
     "start_time": "2021-03-01T20:33:43.562327Z"
    }
   },
   "outputs": [],
   "source": [
    "regex_m = subset_SRS.str.contains(filterTextRegex, case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:02.607304Z",
     "start_time": "2021-03-01T20:34:01.967650Z"
    }
   },
   "outputs": [],
   "source": [
    "subset_SRS = subset_SRS[~regex_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take only values between length 2 and 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:06.832954Z",
     "start_time": "2021-03-01T20:34:02.610146Z"
    }
   },
   "outputs": [],
   "source": [
    "attribute_wc = subset_SRS.str.count(' ') + 1\n",
    "wc_m = (attribute_wc >= 2) & (attribute_wc <= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:07.404726Z",
     "start_time": "2021-03-01T20:34:06.836246Z"
    }
   },
   "outputs": [],
   "source": [
    "subset_SRS = subset_SRS[wc_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out test set examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:07.669039Z",
     "start_time": "2021-03-01T20:34:07.407861Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../results/validation/{model}/validation_SRSs.txt'.format(model=model_iter), 'r') as f:\n",
    "    test_srs = [line.rstrip('\\n') for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:08.270627Z",
     "start_time": "2021-03-01T20:34:07.671915Z"
    }
   },
   "outputs": [],
   "source": [
    "test_m = ~subset_SRS.index.get_level_values(0).isin(test_srs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:08.853159Z",
     "start_time": "2021-03-01T20:34:08.273247Z"
    }
   },
   "outputs": [],
   "source": [
    "subset_SRS = subset_SRS[test_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace whitespace with ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:12.450759Z",
     "start_time": "2021-03-01T20:34:08.855948Z"
    }
   },
   "outputs": [],
   "source": [
    "subset_SRS = subset_SRS.str.replace('\\s+', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:12.712320Z",
     "start_time": "2021-03-01T20:34:12.452809Z"
    }
   },
   "outputs": [],
   "source": [
    "subset_df = pd.DataFrame(subset_SRS).reset_index()\n",
    "subset_df.columns = ['srs', 'attribute', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:13.045794Z",
     "start_time": "2021-03-01T20:34:12.714410Z"
    }
   },
   "outputs": [],
   "source": [
    "subset_df['original_attribute'] = subset_df['attribute']\n",
    "AttribToGroupNameS = grouping_df.groupby('attribute')['GroupName'].first()\n",
    "subset_df['attribute'] = AttribToGroupNameS[subset_df['original_attribute'].values].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:13.144868Z",
     "start_time": "2021-03-01T20:34:13.048125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srs</th>\n",
       "      <th>attribute</th>\n",
       "      <th>value</th>\n",
       "      <th>original_attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRS1024493</td>\n",
       "      <td>Species</td>\n",
       "      <td>Camellia oleifera</td>\n",
       "      <td>SCIENTIFIC_NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRS568274</td>\n",
       "      <td>Species</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>nat-host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERS1412828</td>\n",
       "      <td>Species</td>\n",
       "      <td>Pundamilia nyererei</td>\n",
       "      <td>SCIENTIFIC_NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRS1219231</td>\n",
       "      <td>Species</td>\n",
       "      <td>Salmonella enterica subsp. enterica</td>\n",
       "      <td>SCIENTIFIC_NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRS1219231</td>\n",
       "      <td>Species</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>host</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          srs attribute                                value  \\\n",
       "0  SRS1024493   Species                    Camellia oleifera   \n",
       "1   SRS568274   Species                         Homo sapiens   \n",
       "2  ERS1412828   Species                  Pundamilia nyererei   \n",
       "3  SRS1219231   Species  Salmonella enterica subsp. enterica   \n",
       "4  SRS1219231   Species                         Homo sapiens   \n",
       "\n",
       "  original_attribute  \n",
       "0    SCIENTIFIC_NAME  \n",
       "1           nat-host  \n",
       "2    SCIENTIFIC_NAME  \n",
       "3    SCIENTIFIC_NAME  \n",
       "4               host  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/val split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start by pulling out only samples that are in our dataset from technical metadata, that has studies in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:21.255445Z",
     "start_time": "2021-03-01T20:34:13.147152Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_srs_m = allSRS.index.get_level_values(0).unique()\n",
    "technical_meta_data_df_sub = technical_meta_data_df[technical_meta_data_df.Sample.isin(valid_srs_m)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get unique studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:23.587731Z",
     "start_time": "2021-03-01T20:34:21.257567Z"
    }
   },
   "outputs": [],
   "source": [
    "study_s = technical_meta_data_df_sub['Study'].drop_duplicates()  # Get unique studies that can be found in allSRS\n",
    "num_studies = len(study_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select studies to use to train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:23.723006Z",
     "start_time": "2021-03-01T20:34:23.590017Z"
    }
   },
   "outputs": [],
   "source": [
    "train_test_ratio = 0.8\n",
    "train_n = int(num_studies * train_test_ratio)  # Number of training studies\n",
    "train_studies = study_s.sample(n = train_n, random_state = 0).values  # pick those training studies randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:25.182975Z",
     "start_time": "2021-03-01T20:34:23.726947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Label these studies with a column\n",
    "technical_meta_data_df_sub['Train'] = technical_meta_data_df_sub['Study'].isin(train_studies).values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:25.579708Z",
     "start_time": "2021-03-01T20:34:25.191644Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the ids for the training and test samples\n",
    "train_mask = technical_meta_data_df_sub['Train']\n",
    "train_samples = technical_meta_data_df_sub['Sample'][train_mask].values  # IDs for training set\n",
    "val_samples = technical_meta_data_df_sub['Sample'][~train_mask].values  # IDs for test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training and val dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:25.673427Z",
     "start_time": "2021-03-01T20:34:25.582277Z"
    }
   },
   "outputs": [],
   "source": [
    "nDupTextMax = 1000\n",
    "cap_size = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:26.936149Z",
     "start_time": "2021-03-01T20:34:25.676636Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = subset_df[subset_df.srs.isin(train_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:28.464175Z",
     "start_time": "2021-03-01T20:34:26.938916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Canis lupus familiaris    1000\n",
       "Homo sapiens              1000\n",
       "Glycine max               1000\n",
       "Oryctolagus cuniculus     1000\n",
       "Staphylococcus aureus     1000\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cap how many of a given entity we want to use\n",
    "train_df = train_df.sample(train_df.shape[0])\n",
    "dedup_train_df = train_df.groupby(['value']).head(n = nDupTextMax)\n",
    "dedup_train_df['value'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:28.859257Z",
     "start_time": "2021-03-01T20:34:28.466608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Balance the classes with class cap\n",
    "final_train_df = dedup_train_df.sample(dedup_train_df.shape[0]).groupby('attribute').head(n = cap_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:28.953825Z",
     "start_time": "2021-03-01T20:34:28.862221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training examples is 133697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age                  20000\n",
       "Cell type            20000\n",
       "Species              20000\n",
       "Tissue               20000\n",
       "Strain               20000\n",
       "Genotype             14912\n",
       "Platform              7467\n",
       "Condition/Disease     5382\n",
       "Data type             3254\n",
       "Sex                   2047\n",
       "Protocol               635\n",
       "Name: attribute, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The number of training examples is %d\" % (final_train_df.shape[0]))\n",
    "train_counts = final_train_df.attribute.value_counts()\n",
    "display(train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:29.417120Z",
     "start_time": "2021-03-01T20:34:28.957310Z"
    }
   },
   "outputs": [],
   "source": [
    "val_df = subset_df[subset_df.srs.isin(val_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:30.071932Z",
     "start_time": "2021-03-01T20:34:29.419987Z"
    }
   },
   "outputs": [],
   "source": [
    "val_df = val_df.sample(val_df.shape[0])\n",
    "val_df = subset_df[subset_df.srs.isin(val_samples)]\n",
    "dedup_val_df = val_df.groupby(['value']).head(n = nDupTextMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:30.220052Z",
     "start_time": "2021-03-01T20:34:30.074393Z"
    }
   },
   "outputs": [],
   "source": [
    "final_val_df = dedup_val_df.sample(dedup_val_df.shape[0]).groupby('attribute').head(n = cap_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:30.303734Z",
     "start_time": "2021-03-01T20:34:30.223459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell type            20000\n",
       "Species              20000\n",
       "Tissue               20000\n",
       "Age                   9292\n",
       "Strain                7923\n",
       "Genotype              4747\n",
       "Platform              1590\n",
       "Condition/Disease     1565\n",
       "Data type             1543\n",
       "Sex                    853\n",
       "Protocol               178\n",
       "Name: attribute, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_counts = final_val_df.attribute.value_counts()\n",
    "display(val_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:30.400940Z",
     "start_time": "2021-03-01T20:34:30.306288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6039035539414964"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual training and test split\n",
    "final_train_df.shape[0]/(final_train_df.shape[0] + final_val_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:30.922901Z",
     "start_time": "2021-03-01T20:34:30.405487Z"
    }
   },
   "outputs": [],
   "source": [
    "final_train_df.to_pickle('../results/training/{model}/revision/10_training_examples.pickle'.format(model = model_iter))\n",
    "final_val_df.to_pickle('../results/training/{model}/revision/10_test_examples.pickle'.format(model = model_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Supp. Figure 1B</font> Class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:31.402404Z",
     "start_time": "2021-03-01T20:34:30.925461Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "counts_df = pd.concat([pd.DataFrame(train_counts), pd.DataFrame(val_counts)], axis=1)\n",
    "counts_df.to_csv('../doc/figures/Supplementary/Supp_Figure1B.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:31.473115Z",
     "start_time": "2021-03-01T20:34:31.405180Z"
    }
   },
   "outputs": [],
   "source": [
    "nr_hidden = 64 \n",
    "max_length = 7 # 95% percentile of training phrase length from NCIT\n",
    "dropout = 0.5\n",
    "learn_rate = 0.001 # General NN config\n",
    "nb_epoch = 1\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:31.715904Z",
     "start_time": "2021-03-01T20:34:31.475543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sex', 'Age', 'Strain', 'Cell type', 'Condition/Disease',\n",
       "       'Genotype', 'Platform', 'Species', 'Protocol', 'Data type',\n",
       "       'Tissue'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classNames = AttribToGroupNameS.unique()\n",
    "classNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:31.976651Z",
     "start_time": "2021-03-01T20:34:31.718291Z"
    }
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(classNames)\n",
    "nr_classes=len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:32.131137Z",
     "start_time": "2021-03-01T20:34:31.978884Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm_shape={'nr_hidden': 64, 'max_length': max_length, 'nr_class': nr_classes}\n",
    "lstm_settings={'dropout': 0.5, 'lr': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:32.196264Z",
     "start_time": "2021-03-01T20:34:32.134040Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = nlp.vocab.vectors.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:49.359061Z",
     "start_time": "2021-03-01T20:34:32.199477Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133697/133697 [00:09<00:00, 14161.22it/s]\n",
      "100%|██████████| 87691/87691 [00:04<00:00, 18116.58it/s]\n",
      "100%|██████████| 133697/133697 [00:01<00:00, 93835.40it/s]\n",
      "100%|██████████| 87691/87691 [00:01<00:00, 79965.65it/s]\n"
     ]
    }
   ],
   "source": [
    "train_texts = final_train_df.value.tolist()\n",
    "dev_texts = final_val_df.value.tolist()\n",
    "\n",
    "train_labels = keras.utils.to_categorical(le.transform(final_train_df.attribute.values))\n",
    "dev_labels = keras.utils.to_categorical(le.transform(final_val_df.attribute.values))\n",
    "\n",
    "train_docs = list(tqdm(nlp.pipe(train_texts,n_threads=32),total=len(train_texts)))\n",
    "dev_docs = list(tqdm(nlp.pipe(dev_texts,n_threads=32),total=len(dev_texts)))\n",
    "\n",
    "train_X = get_features(train_docs, lstm_shape['max_length'])\n",
    "dev_X = get_features(dev_docs, lstm_shape['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:34:49.595168Z",
     "start_time": "2021-03-01T20:34:49.364876Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('../results/training/{model}/revision/1_grams/classes.npy'.format(model = model_iter), le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:35:13.172499Z",
     "start_time": "2021-03-01T20:34:49.598470Z"
    }
   },
   "outputs": [],
   "source": [
    "model = compile_lstm(embeddings, lstm_shape, lstm_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:35:13.423239Z",
     "start_time": "2021-03-01T20:35:13.175366Z"
    }
   },
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "with open('../results/training/{model}/revision/10_model_summary.txt'.format(model = model_iter), 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:37:38.808266Z",
     "start_time": "2021-03-01T20:35:13.426144Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture keras_stdout\n",
    "lstm = model.fit(train_X, train_labels, validation_data = (dev_X, dev_labels),\n",
    "          nb_epoch = nb_epoch, verbose = 1, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:37:39.580073Z",
     "start_time": "2021-03-01T20:37:38.811449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021_03_01'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "today = x.strftime(\"%Y_%m_%d\")\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:37:53.783447Z",
     "start_time": "2021-03-01T20:37:39.583016Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm.model.save('../models/revision/{model}_{date}_v5.h5'.format(model = model_iter, date=today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:37:53.942850Z",
     "start_time": "2021-03-01T20:37:53.785888Z"
    }
   },
   "outputs": [],
   "source": [
    "keras_stdout_str = keras_stdout.stdout\n",
    "textfile = open('../results/training/{model}/revision/10_keras_out.txt'.format(model = model_iter), 'w')\n",
    "textfile.write(keras_stdout_str)\n",
    "textfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_PredictMEE",
   "language": "python",
   "name": "predictmee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
