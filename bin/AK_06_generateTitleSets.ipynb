{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Generating-and-evaluating-validation\" data-toc-modified-id=\"Generating-and-evaluating-validation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Generating and evaluating validation</a></span></li><li><span><a href=\"#Set-up\" data-toc-modified-id=\"Set-up-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Set-up</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-necessary-packages\" data-toc-modified-id=\"Import-necessary-packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import necessary packages</a></span></li><li><span><a href=\"#Read-in-key-value-pairs-and-create-pandas-dataframe\" data-toc-modified-id=\"Read-in-key-value-pairs-and-create-pandas-dataframe-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Read in key-value pairs and create pandas dataframe</a></span></li><li><span><a href=\"#Keep-only-samples-with-a-TITLE-longer-than-certain-length-and-have-valid-data\" data-toc-modified-id=\"Keep-only-samples-with-a-TITLE-longer-than-certain-length-and-have-valid-data-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Keep only samples with a TITLE longer than certain length and have valid data</a></span></li><li><span><a href=\"#Select-model-type\" data-toc-modified-id=\"Select-model-type-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Select model type</a></span></li></ul></li><li><span><a href=\"#Process-TITLEs-into-validation-sets\" data-toc-modified-id=\"Process-TITLEs-into-validation-sets-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Process TITLEs into validation sets</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loop-through-each-class-to-generate-validation-sets\" data-toc-modified-id=\"Loop-through-each-class-to-generate-validation-sets-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Loop through each class to generate validation sets</a></span></li></ul></li><li><span><a href=\"#Pull-out-the-SRS's-of-all-validation-examples-to-holdout-from-training-and-testing-model\" data-toc-modified-id=\"Pull-out-the-SRS's-of-all-validation-examples-to-holdout-from-training-and-testing-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Pull out the SRS's of all validation examples to holdout from training and testing model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Generating and evaluating validation\n",
    "Adam Klie<br>\n",
    "12/08/2019<br>\n",
    "Script to predict generate and then evaluate prediction on validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T21:11:28.919754Z",
     "start_time": "2021-02-15T21:11:27.429688Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Read in key-value pairs and create pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T21:11:39.085956Z",
     "start_time": "2021-02-15T21:11:28.923139Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SRA BioSample key-value pairs\n",
    "SRS_dir = \"../data/sra/allSRS_05_15_2018.pickle\"\n",
    "allSRS = pd.read_pickle(SRS_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T21:11:58.967295Z",
     "start_time": "2021-02-15T21:11:39.088108Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SRS_df = pd.DataFrame(allSRS).reset_index()\n",
    "SRS_df.columns = ['srs', 'attribute', 'value']\n",
    "SRS_df = SRS_df.set_index('srs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Keep only samples with a TITLE longer than certain length and have valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:30:28.872900Z",
     "start_time": "2021-02-16T07:30:28.865959Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title_len = 5 # min length of titles to predict on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:31:42.504425Z",
     "start_time": "2021-02-16T07:30:29.376220Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SRS_df['word_count'] = (SRS_df['value'].str.count(' ') + 1)\n",
    "validation_srs = SRS_df[(SRS_df['attribute'].isin(['TITLE'])) & (SRS_df['word_count'] >= title_len)].index\n",
    "validation_all = SRS_df.loc[validation_srs]#.sample(validation_srs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:37:50.246417Z",
     "start_time": "2021-02-16T07:37:37.772560Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Filter out any samples with non-usable values and unigrams (optional)\n",
    "filterTextList = ['not collected','not applicable','missing','n[/]?a','unknown', '-', '--', 'none', 'no']\n",
    "filterTextRegex = \"|\".join(map(lambda myStr:'(?:{})'.format(myStr), filterTextList))\n",
    "filter_mask = validation_all['value'].str.contains(filterTextRegex, case=False)\n",
    "validation_all = validation_all[~filter_mask]\n",
    "\n",
    "# Optional (for revision)\n",
    "# len_mask = validation_all['word_count'] > 1\n",
    "# validation_all = validation_all[~filter_mask & len_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Select model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:37:54.753271Z",
     "start_time": "2021-02-16T07:37:54.746294Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_iter = '11_class'\n",
    "save_dir = '../results/validation/{model}/revision/0.9'.format(model=model_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:41:52.742967Z",
     "start_time": "2021-02-16T07:41:52.714616Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouping = pd.read_csv('../results/embedding/{model}/entity_merging.csv'.format(model=model_iter), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:41:53.582101Z",
     "start_time": "2021-02-16T07:41:53.570475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "groups = grouping[grouping[\"I\"] == 0][[\"attribute\", \"GroupName\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Process TITLEs into validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Loop through each class to generate validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:42:07.324573Z",
     "start_time": "2021-02-16T07:41:54.698600Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for group in groups.iterrows():\n",
    "    srs_class = (group[1].values[0])\n",
    "    predicted_class = (group[1].values[1])\n",
    "    sub_groups = grouping[grouping[\"GroupName\"] == predicted_class][\"attribute\"].values\n",
    "    \n",
    "    # Get a dataframe with the class values to try to predict for this specific class\n",
    "    tmp_df = validation_all[validation_all['attribute'] == srs_class]\n",
    "    #tmp_df = validation_all[validation_all['attribute'].isin(sub_groups)]\n",
    "    \n",
    "    # Cap attributes to get no duplicates and max 1000\n",
    "    nDupTextMax = 10  # number of duplicate values allowed\n",
    "    numSamples = 1000  # number of samples to evaluate for a given class\n",
    "    total_samples = tmp_df.groupby(['value']).head(n = nDupTextMax).shape[0]\n",
    "    if min(numSamples, total_samples) == 0:\n",
    "        continue\n",
    "    class_validation = tmp_df.groupby(['value']).head(n = nDupTextMax).sample(min(numSamples, total_samples))\n",
    "    class_validation.shape\n",
    "\n",
    "    # Get the TITLES for this validation set\n",
    "    validation_sample_ids = class_validation.index\n",
    "    validation_samples = SRS_df.loc[validation_sample_ids]\n",
    "    validation_titles = validation_samples[\n",
    "        validation_samples['attribute'].isin(['TITLE'])].reset_index().set_index(['srs', 'attribute'])\n",
    "    validation_set = validation_titles['value']  # get a series object compatible with prediction script\n",
    "    \n",
    "    # Fix for saving\n",
    "    predicted_class = predicted_class.replace('/', '_')\n",
    "    predicted_class = predicted_class.replace(' ', '_')\n",
    "        \n",
    "    # Save as pickle objects\n",
    "    class_validation.to_pickle('{dir}/{myclass}_validation_values.pickle'.format(dir=save_dir, \n",
    "                                                                                 myclass=predicted_class))\n",
    "    validation_set.to_pickle('{dir}/{myclass}_validation_set.pickle'.format(dir=save_dir, \n",
    "                                                                            myclass=predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pull out the SRS's of all validation examples to holdout from training and testing model\n",
    "Can only run once validation sets have been generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:42:07.405310Z",
     "start_time": "2021-02-16T07:42:07.329698Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species 1000\n",
      "Strain 1000\n",
      "Cell_type 1000\n",
      "Genotype 1000\n",
      "Condition_Disease 650\n",
      "Tissue 1000\n",
      "Sex 172\n",
      "Age 1000\n",
      "Data_type 90\n",
      "Platform 2\n",
      "Protocol 194\n"
     ]
    }
   ],
   "source": [
    "validations = groups[\"GroupName\"].values\n",
    "test_SRSs = []\n",
    "for valid in validations:\n",
    "    valid = valid.replace('/', '_')\n",
    "    valid = valid.replace(' ', '_')\n",
    "    try:\n",
    "        curr_df = pd.read_pickle('{dir}/{myclass}_validation_set.pickle'.format(dir=save_dir, myclass = valid))\n",
    "        curr_SRSs = list(curr_df.index.get_level_values('srs'))\n",
    "        print(valid, len(curr_SRSs))\n",
    "        test_SRSs = test_SRSs + curr_SRSs\n",
    "    except:\n",
    "        print('{dir}/{myclass}_validation_set.pickle does not exist!'.format(dir=save_dir,myclass = valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:32:52.167623Z",
     "start_time": "2021-02-16T07:32:52.161444Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_list = set(test_SRSs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T03:11:01.368173Z",
     "start_time": "2021-01-11T03:11:01.294375Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('{dir}/validation_SRSs.txt'.format(dir=save_dir), 'w') as f:\n",
    "    f.writelines('\\n'.join(test_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_PredictMEE",
   "language": "python",
   "name": "predictmee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
