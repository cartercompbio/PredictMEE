{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Predicting-Entities\" data-toc-modified-id=\"Predicting-Entities-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Predicting Entities<br></a></span></li><li><span><a href=\"#Set-up\" data-toc-modified-id=\"Set-up-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Set-up</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-necessary-packages\" data-toc-modified-id=\"Import-necessary-packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import necessary packages</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Import-trained-model,-word-embedding,-and-data-to-build-validation-data-of-off\" data-toc-modified-id=\"Import-trained-model,-word-embedding,-and-data-to-build-validation-data-of-off-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Import trained model, word embedding, and data to build validation data of off</a></span><ul class=\"toc-item\"><li><span><a href=\"#Trained-NER-model\" data-toc-modified-id=\"Trained-NER-model-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Trained NER model</a></span></li><li><span><a href=\"#Word-embedding-model\" data-toc-modified-id=\"Word-embedding-model-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Word embedding model</a></span></li><li><span><a href=\"#Metadata\" data-toc-modified-id=\"Metadata-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Metadata</a></span></li></ul></li></ul></li><li><span><a href=\"#Predict-metadata-for-each-class\" data-toc-modified-id=\"Predict-metadata-for-each-class-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Predict metadata for each class</a></span><ul class=\"toc-item\"><li><span><a href=\"#Iterate-through-each-class-(run-the-following-chunk-for-each-class)\" data-toc-modified-id=\"Iterate-through-each-class-(run-the-following-chunk-for-each-class)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Iterate through each class (run the following chunk for each class)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Breaking-up-into-sentences\" data-toc-modified-id=\"Breaking-up-into-sentences-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Breaking up into sentences</a></span></li><li><span><a href=\"#Baseline-emission\" data-toc-modified-id=\"Baseline-emission-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Baseline emission</a></span></li><li><span><a href=\"#Prediction-loop\" data-toc-modified-id=\"Prediction-loop-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Prediction loop</a></span></li><li><span><a href=\"#Get-only-those-greater-than-2-grams\" data-toc-modified-id=\"Get-only-those-greater-than-2-grams-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Get only those greater than 2-grams</a></span></li><li><span><a href=\"#Take-highest-probability-class\" data-toc-modified-id=\"Take-highest-probability-class-3.1.5\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>Take highest probability class</a></span></li><li><span><a href=\"#Take-highest-probability-overlapping-n-gram\" data-toc-modified-id=\"Take-highest-probability-overlapping-n-gram-3.1.6\"><span class=\"toc-item-num\">3.1.6&nbsp;&nbsp;</span>Take highest probability overlapping n-gram</a></span></li><li><span><a href=\"#Save-to-pickle-object\" data-toc-modified-id=\"Save-to-pickle-object-3.1.7\"><span class=\"toc-item-num\">3.1.7&nbsp;&nbsp;</span>Save to pickle object</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Predicting Entities<br>\n",
    "Adam Klie<br>\n",
    "11/02/2019<br>\n",
    "Script to predict entities in from trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T08:06:22.959893Z",
     "start_time": "2021-02-16T08:05:54.751885Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Data visualization\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from string import punctuation\n",
    "\n",
    "# Neural nets\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T08:06:22.991670Z",
     "start_time": "2021-02-16T08:06:22.963826Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to embed tokens from text into word embedding space\n",
    "def get_features(docs, max_length):\n",
    "    docs = list(docs)\n",
    "    Xs = np.zeros((len(docs), max_length), dtype='int32')\n",
    "    for i, doc in enumerate(docs):\n",
    "        j = 0\n",
    "        for token in doc:\n",
    "            vector_id = token.vocab.vectors.find(key=token.orth)\n",
    "            if vector_id >= 0:\n",
    "                Xs[i, j] = vector_id\n",
    "            else:\n",
    "                Xs[i, j] = 0\n",
    "            j += 1\n",
    "            if j >= max_length:\n",
    "                break\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import trained model, word embedding, and data to build validation data of off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T08:52:34.041720Z",
     "start_time": "2021-02-16T08:52:34.020666Z"
    }
   },
   "outputs": [],
   "source": [
    "model_iter = '11_class'\n",
    "model_date = '2021_02_16'\n",
    "grouping = pd.read_csv('../results/embedding/{model}/0.8_entity_merging.csv'.format(model=model_iter), index_col=0)\n",
    "groups = grouping[grouping[\"I\"] == 0][\"GroupName\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T08:53:04.291052Z",
     "start_time": "2021-02-16T08:52:42.654167Z"
    }
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.classes_ = np.load('../results/training/{model}/revision/1_grams/classes.npy'.format(model = model_iter))\n",
    "model = load_model('../models/revision/1_grams/{model}_{date}.h5'.format(model = model_iter, date=model_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T08:08:33.402897Z",
     "start_time": "2021-02-16T08:07:00.318806Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../data/wikipedia-pubmed-and-PMC-w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T08:08:52.550033Z",
     "start_time": "2021-02-16T08:08:33.406705Z"
    }
   },
   "outputs": [],
   "source": [
    "SRS_dir = \"../data/sra/allSRS_05_15_2018.pickle\"\n",
    "allSRS = pd.read_pickle(SRS_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict metadata for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T08:53:49.623100Z",
     "start_time": "2021-02-16T08:53:49.617374Z"
    }
   },
   "outputs": [],
   "source": [
    "iter_groups = iter(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through each class (run the following chunk for each class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:20.749976Z",
     "start_time": "2021-02-16T09:01:20.737353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Protocol'"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_class = next(iter_groups)\n",
    "validation_class = validation_class.replace(' ', '_')\n",
    "validation_class = validation_class.replace('/', '_')\n",
    "validation_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:20.764578Z",
     "start_time": "2021-02-16T09:01:20.753266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in validation data for a specific class to predict on\n",
    "filename = '../results/validation/{model}/{myclass}_validation_set.pickle'.format(model = model_iter, \n",
    "                                                                                  myclass = validation_class)\n",
    "validation_data = pd.read_pickle(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking up into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:20.778878Z",
     "start_time": "2021-02-16T09:01:20.769305Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "processed_test = validation_data.str.split('[;.,]', expand = True).stack()\n",
    "processed_test = processed_test.str.replace('\\s+', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:20.791350Z",
     "start_time": "2021-02-16T09:01:20.782041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the empty state to use as baseline probability emission\n",
    "val_docs = list(nlp.pipe(' '))\n",
    "val_X = get_features(val_docs, max_length = model.input_shape[1])\n",
    "emptyState = model.predict_proba(val_X)[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:21.811353Z",
     "start_time": "2021-02-16T09:01:20.794180Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 21.39it/s]\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "rows = []\n",
    "key_list = []\n",
    "for i, (key, sent) in enumerate(tqdm(processed_test.items(), total=len(processed_test))):\n",
    "    \n",
    "    # Sentence preprocessing\n",
    "    #sent = re.sub(r'[^a-zA-Z0-9]+', ' ', sent)  # remove non alpha numeric characters\n",
    "    tokens = re.split(pattern = ' ', string = sent)  # tokenize the description\n",
    "    tokens = list(filter(lambda token:(token!='') and (token not in stopWords), tokens))  # filter out stopwords\n",
    "    sent = ' '.join(tokens)\n",
    "    \n",
    "    n_gram_max = min([len(tokens), 7])\n",
    "    for n_gram in range(1, n_gram_max + 1):\n",
    "        \n",
    "        # Get prediction for all current n-grams\n",
    "        grams = list(map(lambda L:\" \".join(L), list(ngrams(tokens, n_gram))))  \n",
    "        val_docs = list(nlp.pipe(grams))  # get spacy objects for each token passed in\n",
    "        val_X = get_features(val_docs, max_length = model.input_shape[1])\n",
    "        predictM = model.predict_proba(val_X)\n",
    "        \n",
    "        # Take only those n-grams that have a total probability greater than the empty state + 0.01\n",
    "        # and also have two tokens present in word-embedding\n",
    "        tmp_df = pd.DataFrame(data = predictM, columns = le.classes_, index = grams)\n",
    "        empty_mask = (tmp_df - emptyState).abs().sum(axis=1) < 0.01\n",
    "        moreThanTwoValToken_mask = (val_X != 0).sum(axis=1) >= 2\n",
    "        tmp_df[empty_mask&moreThanTwoValToken_mask] = 0\n",
    "        \n",
    "        # Set up keys for dataframe with probabilities of each n-gram, will be useful later\n",
    "        for j, gram in enumerate(tmp_df.index):\n",
    "            i_end = j + n_gram\n",
    "            textBefore = \" \".join(tokens[:j]) + ('' if j==0 else ' ')\n",
    "            start_char_pos = len(textBefore)\n",
    "            key_list.append(key + (i, sent, n_gram, j, i_end, gram, start_char_pos)) \n",
    "            rows.append(tmp_df.iloc[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:21.873219Z",
     "start_time": "2021-02-16T09:01:21.817572Z"
    }
   },
   "outputs": [],
   "source": [
    "proba_df = pd.concat(rows, keys = key_list, axis = 1).T\n",
    "proba_df.index.names = ['srs', 'attribute', 'sentence_number', 'kthSrs', \n",
    "                        'orig_text', 'n-gram_length', 'word_start', 'word_end', 'token', \n",
    "                        'starting_char_pos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get only those greater than 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:21.884798Z",
     "start_time": "2021-02-16T09:01:21.878726Z"
    }
   },
   "outputs": [],
   "source": [
    "textS = pd.Series(proba_df.index.get_level_values('orig_text').unique())\n",
    "textM = textS.str.count(' ') >= 0\n",
    "selectedTexts = textS[textM].values # get the original texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:21.897082Z",
     "start_time": "2021-02-16T09:01:21.888527Z"
    }
   },
   "outputs": [],
   "source": [
    "n_threshold = 1\n",
    "proba_sub = proba_df[(proba_df.index.get_level_values('n-gram_length') >= n_threshold) &\n",
    "                     (proba_df.index.get_level_values('orig_text').isin(selectedTexts))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take highest probability class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:21.913090Z",
     "start_time": "2021-02-16T09:01:21.900699Z"
    }
   },
   "outputs": [],
   "source": [
    "max_proba = proba_sub.max(axis=1)\n",
    "second_proba = proba_sub.quantile(0.999, interpolation='lower', axis = 1)\n",
    "scoreMargin_m = (max_proba-second_proba) > 0.1  # proba difference between 1st and 2nd must be greater than 0.1\n",
    "m_val = scoreMargin_m & (~proba_sub.index.get_level_values('token').str.contains('[0-9 ]+ [0-9 ]+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:21.931009Z",
     "start_time": "2021-02-16T09:01:21.916088Z"
    }
   },
   "outputs": [],
   "source": [
    "tmpDf = pd.DataFrame({'predicted':proba_sub[m_val].idxmax(axis=1),'score':proba_sub[m_val].max(axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:21.962183Z",
     "start_time": "2021-02-16T09:01:21.934054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "scoreSortedDf = tmpDf[m_val].sort_values(['orig_text','word_start','score'], ascending = False).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take highest probability overlapping n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:21.975325Z",
     "start_time": "2021-02-16T09:01:21.965401Z"
    }
   },
   "outputs": [],
   "source": [
    "v = scoreSortedDf.copy()\n",
    "scoreSortedDf = scoreSortedDf.assign(OverlapGroup=(len(processed_test)*(v.kthSrs)+ \n",
    "                                          (v.word_end - v.word_start.shift(-1)).shift().lt(0).cumsum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:22.010010Z",
     "start_time": "2021-02-16T09:01:21.978581Z"
    }
   },
   "outputs": [],
   "source": [
    "hitDf=scoreSortedDf.sort_values(['OverlapGroup','score'],ascending=False).drop_duplicates(['OverlapGroup','predicted']\n",
    "                                                                                   ).sort_values('orig_text')\n",
    "hitDf['token_len']=hitDf['token'].str.len()\n",
    "hitDf['recovered_txt']=hitDf.apply(\n",
    "    lambda tmpS2:tmpS2.loc['orig_text'][tmpS2.loc['starting_char_pos']:(tmpS2.loc['starting_char_pos']+tmpS2.loc['token_len'])],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T09:01:22.060304Z",
     "start_time": "2021-02-16T09:01:22.012531Z"
    }
   },
   "outputs": [],
   "source": [
    "hitDf.to_pickle('../results/prediction/{model}/revision/0.7/{myclass}_prediction.pickle'.format(model = model_iter, \n",
    "                                                                                   myclass = validation_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_PredictMEE",
   "language": "python",
   "name": "predictmee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
