{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Predicting-Entities\" data-toc-modified-id=\"Predicting-Entities-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Predicting Entities<br></a></span></li><li><span><a href=\"#Set-up\" data-toc-modified-id=\"Set-up-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Set-up</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-necessary-packages\" data-toc-modified-id=\"Import-necessary-packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import necessary packages</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Import-trained-model,-word-embedding,-and-data-to-build-validation-data-of-off\" data-toc-modified-id=\"Import-trained-model,-word-embedding,-and-data-to-build-validation-data-of-off-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Import trained model, word embedding, and data to build validation data of off</a></span><ul class=\"toc-item\"><li><span><a href=\"#Trained-NER-model\" data-toc-modified-id=\"Trained-NER-model-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Trained NER model</a></span></li><li><span><a href=\"#Word-embedding-model\" data-toc-modified-id=\"Word-embedding-model-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Word embedding model</a></span></li><li><span><a href=\"#Metadata\" data-toc-modified-id=\"Metadata-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Metadata</a></span></li></ul></li></ul></li><li><span><a href=\"#Predict-metadata-for-each-class\" data-toc-modified-id=\"Predict-metadata-for-each-class-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Predict metadata for each class</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Predicting Entities<br>\n",
    "Adam Klie<br>\n",
    "11/02/2019<br>\n",
    "Script to predict entities in from trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:47:01.683339Z",
     "start_time": "2021-03-01T20:46:52.524471Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Data visualization\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from string import punctuation\n",
    "\n",
    "# Neural nets\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:47:01.704307Z",
     "start_time": "2021-03-01T20:47:01.687700Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to embed tokens from text into word embedding space\n",
    "def get_features(docs, max_length):\n",
    "    docs = list(docs)\n",
    "    Xs = np.zeros((len(docs), max_length), dtype='int32')\n",
    "    for i, doc in enumerate(docs):\n",
    "        j = 0\n",
    "        for token in doc:\n",
    "            vector_id = token.vocab.vectors.find(key=token.orth)\n",
    "            if vector_id >= 0:\n",
    "                Xs[i, j] = vector_id\n",
    "            else:\n",
    "                Xs[i, j] = 0\n",
    "            j += 1\n",
    "            if j >= max_length:\n",
    "                break\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Import trained model, word embedding, and data to build validation data of off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Trained NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:47:01.972359Z",
     "start_time": "2021-03-01T20:47:01.707148Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_iter = '11_class'\n",
    "model_date = '2021_03_01'\n",
    "grouping = pd.read_csv('../results/embedding/{model}/0.8_entity_merging.csv'.format(model=model_iter), index_col=0)\n",
    "groups = grouping[grouping[\"I\"] == 0][\"GroupName\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T21:26:13.799262Z",
     "start_time": "2021-03-01T21:25:47.344168Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.classes_ = np.load('../results/training/{model}/revision/classes.npy'.format(model = model_iter))\n",
    "model = load_model('../models/revision/{model}_{date}_v4.h5'.format(model = model_iter, date=model_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Word embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:48:19.285276Z",
     "start_time": "2021-03-01T20:47:32.436032Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/PredictMEE_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../data/wikipedia-pubmed-and-PMC-w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T20:48:31.869680Z",
     "start_time": "2021-03-01T20:48:19.288215Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SRS_dir = \"../data/sra/allSRS_05_15_2018.pickle\"\n",
    "allSRS = pd.read_pickle(SRS_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Predict metadata for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T21:26:13.805878Z",
     "start_time": "2021-03-01T21:26:13.802824Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trial_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T21:31:23.864309Z",
     "start_time": "2021-03-01T21:27:13.234576Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1517/1517 [00:39<00:00, 38.68it/s]\n",
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  0%|          | 5/1633 [00:00<00:33, 48.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1633/1633 [00:40<00:00, 40.79it/s]\n",
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  0%|          | 3/1078 [00:00<00:38, 27.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [00:27<00:00, 38.80it/s]\n",
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  1%|          | 5/808 [00:00<00:20, 39.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 808/808 [00:24<00:00, 33.05it/s]\n",
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  2%|▏         | 3/158 [00:00<00:05, 29.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition_Disease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:04<00:00, 36.65it/s]\n",
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  0%|          | 5/1432 [00:00<00:35, 39.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tissue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1432/1432 [00:40<00:00, 35.73it/s]\n",
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  2%|▏         | 6/279 [00:00<00:05, 54.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [00:07<00:00, 36.49it/s]\n",
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  0%|          | 2/1366 [00:00<01:33, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1366/1366 [00:36<00:00, 37.21it/s]\n",
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  1%|          | 1/83 [00:00<00:09,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:07<00:00, 11.26it/s]\n",
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  1%|▏         | 5/372 [00:00<00:07, 47.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 372/372 [00:09<00:00, 38.57it/s]\n",
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      " 19%|█▉        | 4/21 [00:00<00:00, 28.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 29.71it/s]\n",
      "/cellar/users/aklie/.local/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "for validation_class in groups:\n",
    "    validation_class = validation_class.replace(' ', '_')\n",
    "    validation_class = validation_class.replace('/', '_')\n",
    "    print(validation_class)\n",
    "\n",
    "    # Read in validation data for a specific class to predict on\n",
    "    filename = '../results/validation/{model}/{myclass}_validation_set.pickle'.format(model = model_iter, \n",
    "                                                                                      myclass = validation_class)\n",
    "    validation_data = pd.read_pickle(filename)\n",
    "\n",
    "    processed_test = validation_data.str.split('[;.,]', expand = True).stack()\n",
    "    processed_test = processed_test.str.replace('\\s+', ' ')\n",
    "\n",
    "    # Predict the empty state to use as baseline probability emission\n",
    "    val_docs = list(nlp.pipe(' '))\n",
    "    val_X = get_features(val_docs, max_length = model.input_shape[1])\n",
    "    emptyState = model.predict_proba(val_X)[0,:]\n",
    "\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    rows = []\n",
    "    key_list = []\n",
    "    for i, (key, sent) in enumerate(tqdm(processed_test.items(), total=len(processed_test))):\n",
    "\n",
    "        # Sentence preprocessing\n",
    "        #sent = re.sub(r'[^a-zA-Z0-9]+', ' ', sent)  # remove non alpha numeric characters\n",
    "        tokens = re.split(pattern = ' ', string = sent)  # tokenize the description\n",
    "        tokens = list(filter(lambda token:(token!='') and (token not in stopWords), tokens))  # filter out stopwords\n",
    "        sent = ' '.join(tokens)\n",
    "\n",
    "        n_gram_max = min([len(tokens), 7])\n",
    "        for n_gram in range(2, n_gram_max + 1):\n",
    "\n",
    "            # Get prediction for all current n-grams\n",
    "            grams = list(map(lambda L:\" \".join(L), list(ngrams(tokens, n_gram))))  \n",
    "            val_docs = list(nlp.pipe(grams))  # get spacy objects for each token passed in\n",
    "            val_X = get_features(val_docs, max_length = model.input_shape[1])\n",
    "            predictM = model.predict_proba(val_X)\n",
    "\n",
    "            # Take only those n-grams that have a total probability greater than the empty state + 0.01\n",
    "            # and also have two tokens present in word-embedding\n",
    "            tmp_df = pd.DataFrame(data = predictM, columns = le.classes_, index = grams)\n",
    "            empty_mask = (tmp_df - emptyState).abs().sum(axis=1) < 0.01\n",
    "            moreThanTwoValToken_mask = (val_X != 0).sum(axis=1) >= 2\n",
    "            tmp_df[empty_mask&moreThanTwoValToken_mask] = 0\n",
    "\n",
    "            # Set up keys for dataframe with probabilities of each n-gram, will be useful later\n",
    "            for j, gram in enumerate(tmp_df.index):\n",
    "                i_end = j + n_gram\n",
    "                textBefore = \" \".join(tokens[:j]) + ('' if j==0 else ' ')\n",
    "                start_char_pos = len(textBefore)\n",
    "                key_list.append(key + (i, sent, n_gram, j, i_end, gram, start_char_pos)) \n",
    "                rows.append(tmp_df.iloc[j])\n",
    "\n",
    "    proba_df = pd.concat(rows, keys = key_list, axis = 1).T\n",
    "    proba_df.index.names = ['srs', 'attribute', 'sentence_number', 'kthSrs', \n",
    "                            'orig_text', 'n-gram_length', 'word_start', 'word_end', 'token', \n",
    "                            'starting_char_pos']\n",
    "\n",
    "    textS = pd.Series(proba_df.index.get_level_values('orig_text').unique())\n",
    "    textM = textS.str.count(' ') >= 0\n",
    "    selectedTexts = textS[textM].values # get the original texts\n",
    "\n",
    "    n_threshold = 2\n",
    "    proba_sub = proba_df[(proba_df.index.get_level_values('n-gram_length') >= n_threshold) &\n",
    "                         (proba_df.index.get_level_values('orig_text').isin(selectedTexts))]\n",
    "\n",
    "    max_proba = proba_sub.max(axis=1)\n",
    "    second_proba = proba_sub.quantile(0.999, interpolation='lower', axis = 1)\n",
    "    scoreMargin_m = (max_proba-second_proba) > 0.1  # proba difference between 1st and 2nd must be greater than 0.1\n",
    "    m_val = scoreMargin_m & (~proba_sub.index.get_level_values('token').str.contains('[0-9 ]+ [0-9 ]+'))\n",
    "\n",
    "    tmpDf = pd.DataFrame({'predicted':proba_sub[m_val].idxmax(axis=1),'score':proba_sub[m_val].max(axis=1)})\n",
    "\n",
    "    scoreSortedDf = tmpDf[m_val].sort_values(['orig_text','word_start','score'], ascending = False).reset_index()\n",
    "\n",
    "    v = scoreSortedDf.copy()\n",
    "    scoreSortedDf = scoreSortedDf.assign(OverlapGroup=(len(processed_test)*(v.kthSrs)+ \n",
    "                                              (v.word_end - v.word_start.shift(-1)).shift().lt(0).cumsum()))\n",
    "\n",
    "    hitDf=scoreSortedDf.sort_values(['OverlapGroup','score'],ascending=False).drop_duplicates(['OverlapGroup','predicted']\n",
    "                                                                                       ).sort_values('orig_text')\n",
    "    hitDf['token_len']=hitDf['token'].str.len()\n",
    "    hitDf['recovered_txt']=hitDf.apply(\n",
    "        lambda tmpS2:tmpS2.loc['orig_text'][tmpS2.loc['starting_char_pos']:(tmpS2.loc['starting_char_pos']+tmpS2.loc['token_len'])],axis=1)\n",
    "\n",
    "    hitDf.to_pickle('../results/prediction/{model}/revision/trial_{trial}/{trial}_{myclass}_prediction.pickle'.format(model = model_iter, \n",
    "                                                                                       trial = trial_num, myclass = validation_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_PredictMEE",
   "language": "python",
   "name": "predictmee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
